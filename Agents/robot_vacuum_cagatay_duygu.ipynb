{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmiqjVBDh4l3"
      },
      "source": [
        "# Intelligent Agents: Reflex-Based Agents for the Vacuum-cleaner World\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undergrads 100 / Graduate students 110\n",
        "\n",
        "Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a PDF file. \n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this assignment you will implement a simulator environment for an automatic vacuum cleaner robot, a set of different reflex-based agent programs, and perform a comparison study for cleaning a single room. Focus on the __cleaning phase__ which starts when the robot is activated and ends when the last dirty square in the room has been cleaned. Someone else will take care of the agent program needed to navigate back to the charging station after the room is clean.\n",
        "\n",
        "## PEAS description of the cleaning phase\n",
        "\n",
        "__Performance Measure:__ Each action costs 1 energy unit. The performance is measured as the sum of the energy units used to clean the whole room.\n",
        "\n",
        "__Environment:__ A room with $n \\times n$ squares where $n = 5$. Dirt is randomly placed on each square with probability $p = 0.2$. For simplicity, you can assume that the agent knows the size and the layout of the room (i.e., it knows $n$). To start, the agent is placed on a random square.\n",
        "\n",
        "__Actuators:__ The agent can clean the current square (action `suck`) or move to an adjacent square by going `north`, `east`, `south`, or `west`.\n",
        "\n",
        "__Sensors:__ Four bumper sensors, one for north, east, south, and west; a dirt sensor reporting dirt in the current square.  \n",
        "\n",
        "\n",
        "## The agent program for a simple randomized agent\n",
        "\n",
        "The agent program is a function that gets sensor information (the current percepts) as the arguments. The arguments are:\n",
        "\n",
        "* A dictionary with boolean entries for the for bumper sensors `north`, `east`, `west`, `south`. E.g., if the agent is on the north-west corner, `bumpers` will be `{\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}`.\n",
        "* The dirt sensor produces a boolean.\n",
        "\n",
        "The agent returns the chosen action as a string.\n",
        "\n",
        "Here is an example implementation for the agent program of a simple randomized agent:  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CAGATAY DUYGU**\n",
        "\n",
        "\n",
        "\n",
        "**48369962**\n"
      ],
      "metadata": {
        "id": "x4A4UzVQSRUd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1a5HTjyh4l9"
      },
      "source": [
        "__Note:__ This is not a rational intelligent agent. It ignores its sensors and may bump into a wall repeatedly or not clean a dirty square. You will be asked to implement rational agents below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpvH3gc3h4mB"
      },
      "source": [
        "# Tasks\n",
        "\n",
        "## General [10 Points]\n",
        "\n",
        "1. Make sure that you use the latest version of this notebook. Sync your forked repository and pull the latest revision. \n",
        "2. Your implementation can use libraries like math, numpy, scipy, but not libraries that implement inteligent agents or complete search algorithms. Try to keep the code simple! In this course, we want to learn about the algorithms and we often do not need to use object-oriented design.\n",
        "3. You notebook needs to be formated professionally. \n",
        "    - Add additional markdown blocks for your description, comments in the code, add tables and use mathplotlib to produce charts where appropriate\n",
        "    - Do not show debugging output or include an excessive amount of output.\n",
        "    - Check that your PDF file is readable. For example, long lines are cut off in the PDF file. You don't have control over page breaks, so do not worry about these.\n",
        "4. Document your code. Add a short discussion of how your implementation works and your design choices.\n",
        "\n",
        "\n",
        "## Task 1: Implement a simulation environment [20 Points]\n",
        "\n",
        "The simple environment above is not very realistic. Your environment simulator needs to follow the PEAS description from above. It needs to:\n",
        "\n",
        "* Initialize the environment by storing the state of each square (clean/dirty) and making some dirty. ([Help with random numbers and arrays in Python](https://github.com/mhahsler/CS7320-AI/blob/master/Python_Code_Examples/random_numbers_and_arrays.ipynb))\n",
        "* Keep track of the agent's position.\n",
        "* Call the agent function repeatedly and provide the agent function with the sensor inputs.  \n",
        "* React to the agent's actions. E.g, by removing dirt from a square or moving the agent around unless there is a wall in the way.\n",
        "* Keep track of the performance measure. That is, track the agent's actions until all dirty squares are clean and count the number of actions it takes the agent to complete the task.\n",
        "\n",
        "The easiest implementation for the environment is to hold an 2-dimensional array to represent if squares are clean or dirty and to call the agent function in a loop until all squares are clean or a predefined number of steps have been reached (i.e., the robot runs out of energy).\n",
        "\n",
        "The simulation environment should be a function like the `simple_environment()` and needs to work with the simple randomized agent program from above. **Use the same environmnt for all your agent implementations in the tasks below.**\n",
        "\n",
        "*Note on debugging:* Debugging is difficult. Make sure your environment prints enough information when you use `verbose = True`. Also, implementing a function that the environment can use to displays the room with dirt and the current position of the robot at every step is very useful.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Environment Matrix:\n",
        "0: clean points,\n",
        "1:dirty points,\n",
        "3:walls,\n",
        "2:obstacles\n",
        "\n",
        "Environment Matrix is defined randomly. Without obstacle situation, all matrix is defined 1,0 values inside and 3 values on the wall."
      ],
      "metadata": {
        "id": "AC5YuZeFselw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomized Agent with displacement values."
      ],
      "metadata": {
        "id": "zj_MP6buxwzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqsDqXh6w1Pi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#delta represents the displacement value. for every action, displacement value is changed\n",
        "\n",
        "def simple_randomized_agent():\n",
        "    actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
        "    chosen_Act = np.random.choice(actions)\n",
        "    if chosen_Act == 'north':\n",
        "        delta = [-1,0]\n",
        "    if chosen_Act == 'east':\n",
        "        delta = [0,1]\n",
        "    if chosen_Act == 'west':\n",
        "        delta = [0,-1]\n",
        "    if chosen_Act == 'south':\n",
        "        delta = [1,0]  \n",
        "    if chosen_Act == 'suck':\n",
        "        delta = [0,0]\n",
        "    return np.array(delta), chosen_Act"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Environment Randomized Agent"
      ],
      "metadata": {
        "id": "RJ6_3s2lx0w0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0: Clean points\n",
        "1: Dirty Points\n",
        "2:Obstacles\n",
        "3:Walls\n",
        "\n"
      ],
      "metadata": {
        "id": "FCGhLnt9yF71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BGqsZk3w1Pj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def simple_environment(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(2, size=(n, n), p=[0.8, 0.2])\n",
        "    #value 2 should be replaced to 3 if there is any obstacle in the environment and another possibility value should be added.\n",
        "    \n",
        "    #3 represents the walls. First and last column and rows of the environment matrix will be all 3.\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "\n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #Defines sensors for the environment. Bumpers will see the walls(3) and obstacles(2) if there is any.\n",
        "      #This case there are only walls. Dirt sensor is defined inside bumpers matrix and represented\n",
        "      #as one \n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==1: bumpers[\"dirt\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==0: bumpers[\"dirt\"]=False\n",
        "        delta, act = agent()\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        print(\"Number of iteration:\")\n",
        "        print(i+1)\n",
        "        print(\"position of robot:\")\n",
        "        print(robot_position)\n",
        "        print(\"Action taken:\")\n",
        "        print(act)\n",
        "        print(\"Environment status after the action\")\n",
        "        print(environment)\n",
        "        print(bumpers)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "#returns the total action required.\n",
        "    return i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwIuaXZow1Pm",
        "outputId": "08f640f6-84ed-45ff-c58b-dd43d4638feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iteration:\n",
            "1\n",
            "position of robot:\n",
            "[3 2]\n",
            "Action taken:\n",
            "suck\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 1 1 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 1 0 1 0 1 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': False, 'dirt': False}\n",
            "Number of iteration:\n",
            "2\n",
            "position of robot:\n",
            "[3 1]\n",
            "Action taken:\n",
            "west\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 1 1 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 1 0 1 0 1 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': False, 'dirt': False}\n",
            "Number of iteration:\n",
            "3\n",
            "position of robot:\n",
            "[3 1]\n",
            "Action taken:\n",
            "west\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 1 1 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 1 0 1 0 1 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n",
            "Number of iteration:\n",
            "4\n",
            "position of robot:\n",
            "[3 1]\n",
            "Action taken:\n",
            "west\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 1 1 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 1 0 1 0 1 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n",
            "Number of iteration:\n",
            "5\n",
            "position of robot:\n",
            "[3 1]\n",
            "Action taken:\n",
            "suck\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 1 1 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 1 0 1 0 1 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import numpy as np\n",
        "n=7\n",
        "simple_environment(n,simple_randomized_agent, max_steps = 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGXV9l3Xh4mG"
      },
      "source": [
        "## Task 2:  Implement a simple reflex agent [10 Points] \n",
        "\n",
        "The simple reflex agent randomly walks around but reacts to the bumper sensor by not bumping into the wall and to dirt with sucking. Implement the agent program as a function.\n",
        "\n",
        "_Note:_ Agents cannot directly use variable in the environment. They only gets the percepts as the arguments to the agent function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obstacle moved around randomly. It does not suck randomly. If it detects dirt in its position, it cleans the dirt. If it gets positive value in its bumpers sensors, it removes the action from its potential actions and select an action from its potential actions randomly"
      ],
      "metadata": {
        "id": "h6cLh_kyTk0d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kwS34gGKtFi"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG9g6WFth4mG"
      },
      "outputs": [],
      "source": [
        "# Your code and description goes here\n",
        "\n",
        "def simple_agent(sensor):\n",
        "    actions = [\"north\", \"east\", \"west\", \"south\"]\n",
        "    chosen_Act = np.random.choice(actions)\n",
        "    \n",
        "    # ACTION REMOVAL\n",
        "    if (chosen_Act == 'north') and (sensor[\"north\"]==True):\n",
        "        actions.remove('north')\n",
        "        chosen_Act = np.random.choice(actions)\n",
        "    if chosen_Act == 'north' and (sensor[\"north\"]==False): chosen_Act='north'\n",
        "\n",
        "    if (chosen_Act == 'east') and (sensor[\"east\"]==True):\n",
        "        actions.remove('east')\n",
        "        chosen_Act = np.random.choice(actions)\n",
        "    if chosen_Act == 'east' and (sensor[\"east\"]==False): chosen_Act='east'        \n",
        "\n",
        "    if (chosen_Act == 'south') and (sensor[\"south\"]==True):\n",
        "        actions.remove('south')\n",
        "        chosen_Act = np.random.choice(actions)\n",
        "    if chosen_Act == 'south' and (sensor[\"south\"]==False): chosen_Act='south' \n",
        "\n",
        "    if (chosen_Act == 'west') and (sensor[\"west\"]==True):\n",
        "        actions.remove('west')\n",
        "        chosen_Act = np.random.choice(actions)\n",
        "    if chosen_Act == 'west' and (sensor[\"west\"]==False): chosen_Act='west' \n",
        "\n",
        "    if sensor[\"dirt\"]==True: chosen_Act='suck'\n",
        "\n",
        "    return chosen_Act\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFsl2Lhc8j69"
      },
      "outputs": [],
      "source": [
        "#SIMPLE ENVIRONMENT IS FOR REFLEX AGENT IS DEFINED:\n",
        "def simple_environment_2(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(2, size=(n, n), p=[0.8, 0.2])\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "    #print(\"First Position of the robot:\")\n",
        "    #print(robot_position)\n",
        "  #print(robot_position)\n",
        "   # south_con, north_con, west_con, east_con = robot_position[0] == 4, \n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #define environmental obstacles. For this case, bumpers will only see the\n",
        "      #walls. Dirt sensor is also defined here.\n",
        "        #reward_space[robot_position[0]+1][robot_position[1]+1]=reward_space[robot_position[0]][robot_position[1]]+1\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "\n",
        "\n",
        "        if environment[robot_position[0]][robot_position[1]]==1: bumpers[\"dirt\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==0: bumpers[\"dirt\"]=False\n",
        "        act = agent(bumpers)\n",
        "        if act == 'east':\n",
        "          delta = [0,1]\n",
        "        if act == 'west':\n",
        "          delta = [0,-1]\n",
        "        if act == 'south':\n",
        "          delta = [1,0]  \n",
        "        if act == 'suck':\n",
        "          delta = [0,0]\n",
        "        if act == 'north':\n",
        "          delta = [-1,0]\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        print(\"Number of iteration:\")\n",
        "        print(i+1)\n",
        "        print(bumpers)\n",
        "        print(\"Action taken:\")\n",
        "        print(act)\n",
        "        print(\"position of robot:\")\n",
        "        print(robot_position)\n",
        "        print(\"Environment status after the action\")\n",
        "        print(environment)\n",
        "        \n",
        "        #print(reward_space)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "        \n",
        "    return i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1d7ea5-1eab-453f-e957-7d6f66c71ec9",
        "id": "Ak72wgfb8j7T"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iteration:\n",
            "1\n",
            "{'north': True, 'east': False, 'south': False, 'west': False, 'dirt': True}\n",
            "Action taken:\n",
            "suck\n",
            "position of robot:\n",
            "[1 4]\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 1 0 3]\n",
            " [3 0 0 0 1 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "Number of iteration:\n",
            "2\n",
            "{'north': True, 'east': False, 'south': False, 'west': False, 'dirt': False}\n",
            "Action taken:\n",
            "south\n",
            "position of robot:\n",
            "[2 4]\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 1 0 3]\n",
            " [3 0 0 0 1 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "Number of iteration:\n",
            "3\n",
            "{'north': False, 'east': False, 'south': False, 'west': False, 'dirt': False}\n",
            "Action taken:\n",
            "west\n",
            "position of robot:\n",
            "[2 3]\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 1 0 3]\n",
            " [3 0 0 0 1 0 3]\n",
            " [3 3 3 3 3 3 3]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import numpy as np\n",
        "n=7\n",
        "simple_environment_2(n,simple_agent, max_steps = 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9buOpV5mh4mG"
      },
      "source": [
        "## Task 3: Implement a model-based reflex agent [20 Points]\n",
        "\n",
        "Model-based agents use a state to keep track of what they have done and perceived so far. Your agent needs to find out where it is located and then keep track of its current location. You also need a set of rules based on the state and the percepts to make sure that the agent will clean the whole room. For example, the agent can move to a corner to determine its location and then it can navigate through the whole room and clean dirty squares.\n",
        "\n",
        "Describe how you define the __agent state__ and how your agent works before implementing it. ([Help with implementing state information on Python](https://github.com/mhahsler/CS7320-AI/blob/master/Python_Code_Examples/store_agent_state_information.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Firstly, robot goes to North-West corner.**\n",
        "\n",
        "**When these two sensor is True, robot know that its position is [1,1]**\n",
        "\n",
        "**A negative reward matrix is defined from robot location.**\n",
        "\n",
        "**Reward space is an array and it is all zeros in the beginning.**\n",
        "\n",
        "**Robot position is reward space is added 1 every iteration.**\n",
        "\n",
        "**Every iteration, robot looks at if there is dirt in its location. If there is it cleans the dirt.**\n",
        "\n",
        "**If there is no dirt, it looks at its neigbor's reward space equivalent. It selects the minimum value and take the action accordingly.**\n",
        "\n",
        "**If there are same values more than 1, agent selects the action randomly.**"
      ],
      "metadata": {
        "id": "BsioUG7pT4yz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97QHUjTmPwLD"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDQ2XBnfPwLE"
      },
      "outputs": [],
      "source": [
        "# Your code and description goes here\n",
        "\n",
        "def find_station(n,robot_position,max_steps):\n",
        "    chosen_Act = 'north'\n",
        "    for i in range(max_steps):\n",
        "        # sensors sensing\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        # rationalizing action\n",
        "        if bumpers[chosen_Act] == True: \n",
        "            chosen_Act = 'west' \n",
        "        else: \n",
        "            chosen_Act = chosen_Act\n",
        "        if bumpers[chosen_Act] == True:\n",
        "            #print('arrived at north-west corner')\n",
        "            #print('saving position as (0,0) to memory')\n",
        "            memory_position = robot_position\n",
        "            break\n",
        "        # act upon chosen action\n",
        "        if chosen_Act == 'east':\n",
        "            delta = [0,1]\n",
        "        if chosen_Act == 'west':\n",
        "            delta = [0,-1]\n",
        "        if chosen_Act == 'south':\n",
        "            delta = [1,0]  \n",
        "        if chosen_Act == 'suck':\n",
        "            delta = [0,0]\n",
        "        if chosen_Act == 'north':\n",
        "            delta = [-1,0]         \n",
        "        # changed position\n",
        "        robot_position = robot_position + delta\n",
        "        #print(robot_position)\n",
        "    return robot_position\n",
        "\n",
        "#Look at the reward values and select minimum value and its act.\n",
        "def reward_based_movement(robot_position, reward_space, actions):\n",
        "    # robot_position = [0, 0]\n",
        "    # actions = {\"east\" : [0,1], \"south\" : [1,0]}\n",
        "    p_pos, p_reward = list(), list()\n",
        "    p_delta = [j for i,j in actions.items()]\n",
        "    for i in range(len(p_delta)):\n",
        "        p_pos.append(np.array(robot_position) + p_delta[i])\n",
        "        p_reward.append(reward_space[p_pos[-1][0]][p_pos[-1][1]])\n",
        "    idx = p_reward.index(min(p_reward)) # find index of the low reward direction\n",
        "    act = list(actions.keys())[idx]\n",
        "    #print(chosen_Act) \n",
        "    #print(reward_space)\n",
        "    return act\n",
        "\n",
        "def modal_based_agent(n, robot_position, max_steps):\n",
        "    env=np.random.choice(2, size=(n, n), p=[0.8, 0.2])\n",
        "    env[0] = [3 for i in range(n)]\n",
        "    env[n-1] = [3 for i in range(n)]\n",
        "    env[:,0] = [3 for i in range(n)]\n",
        "    env[:,n-1]=[3 for i in range(n)]\n",
        "    robot_position_array = list()\n",
        "    reward_space = np.zeros(shape = (n,n))\n",
        "    #print('This is the environment matrix:')\n",
        "    #print(env)\n",
        "    for i in range(max_steps):\n",
        "        # return back all possiblities.\n",
        "        actions = {\"north\" : [-1,0] , \"east\": [0,1], \"west\" : [0,-1], \"south\" : [1, 0]}\n",
        "        reward_space[robot_position[0]][robot_position[1]]=reward_space[robot_position[0]][robot_position[1]]+1\n",
        "        #print(robot_position)\n",
        "        # sensors\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "\n",
        "       \n",
        "        # Obstacle recognition  \n",
        "        if env[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if env[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]-1]==2:bumpers[\"west\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]]==1: bumpers[\"suck\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]]==0: bumpers[\"suck\"]=False\n",
        "      \n",
        "        \n",
        "        # eliminate irrational choices to determine the action:         \n",
        "        if bumpers[\"suck\"] == True: \n",
        "            chosen_Act = 'suck'\n",
        "            #print('sucking')\n",
        "        else:\n",
        "            if bumpers['south'] ==  True: del actions['south']  # actions.remove('south')\n",
        "            if bumpers['east'] ==  True:  del actions['east']   # actions.remove('east')\n",
        "            if bumpers['west'] ==  True:  del actions['west']   # actions.remove('west')\n",
        "            if bumpers['north'] ==  True: del actions['north']  # actions.remove('north')\n",
        "        \n",
        "        # Choosing rational action        \n",
        "            if i == 0: \n",
        "                chosen_Act = np.random.choice(list(actions.keys()))\n",
        "                #print('first step')  # first action is total random chosen from possible paths.\n",
        "            elif bumpers[chosen_Act] == True: \n",
        "                #print('we are at wall: ',robot_position)\n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions) #reward_based_movement\n",
        "            elif chosen_Act == 'suck': \n",
        "                #print(actions)\n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions)\n",
        "                #print('cleaned: ', robot_position)\n",
        "            else: \n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions)\n",
        "                #print('else condition. pure reward based')\n",
        "            \n",
        "        \n",
        "        # act to the chosen action\n",
        "        if chosen_Act == 'east':\n",
        "            delta = [0,1]\n",
        "        if chosen_Act == 'west':\n",
        "            delta = [0,-1]\n",
        "        if chosen_Act == 'south':\n",
        "            delta = [1,0]  \n",
        "        if chosen_Act == 'suck':\n",
        "            delta = [0,0]\n",
        "        if chosen_Act == 'north':\n",
        "            delta = [-1,0]            \n",
        "        if chosen_Act == 'suck':\n",
        "            env[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "            env=env\n",
        "\n",
        "        #if the environment is clean, break the loop.\n",
        "        #if not np.any(env):\n",
        "        if 1 not in env:\n",
        "            print('finished at iteration:', i+1,'steps')\n",
        "            break\n",
        "        \n",
        "        # Moving to new position\n",
        "        robot_position = robot_position + delta\n",
        "        robot_position_array.append(robot_position)\n",
        "        print('iteration')\n",
        "        print(i+1)\n",
        "        print(\"Reward Space\")\n",
        "        print(reward_space) \n",
        "        print(\"Environment\")\n",
        "        print(env)\n",
        "        \n",
        "    return i+1, reward_space          "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=7 \n",
        "bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }\n",
        "robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "robot_position = find_station(n,robot_position,1000000)\n",
        "modal_based_agent(n,robot_position, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I-IKaaYQP5l",
        "outputId": "0c5ba076-c0d3-4a08-9abd-445b6cac0622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration\n",
            "1\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 1 0 3]\n",
            " [3 1 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "2\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 1 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "3\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 2. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 1 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "4\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 1 0 1 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "5\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 0. 0. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 1 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "6\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 2. 0. 0. 0. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 1 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "7\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 2. 1. 0. 0. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 1 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "8\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 2. 1. 1. 0. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "9\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 2. 1. 2. 0. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "iteration\n",
            "10\n",
            "Reward Space\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 2. 1. 2. 1. 0.]\n",
            " [0. 2. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]]\n",
            "Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 1 0 1 3]\n",
            " [3 0 1 0 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, array([[0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 2., 1., 2., 1., 0.],\n",
              "        [0., 2., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X93Mcmomh4mG"
      },
      "source": [
        "## Task 4: Simulation study [30 Points]\n",
        "\n",
        "Compare the performance (the performance measure is defined in the PEAS description above) of the agents using  environments of different size. E.g., $5 \\times 5$, $10 \\times 10$ and\n",
        "$100 \\times 100$. Use 100 random runs for each. Present the results using tables and graphs. Discuss the differences between the agents. \n",
        "([Help with charts and tables in Python](https://github.com/mhahsler/CS7320-AI/blob/master/Python_Code_Examples/charts_and_tables.ipynb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5ksotImh4mH"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV8PML6cz-Kt"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random agent"
      ],
      "metadata": {
        "id": "mr1dg76_0s6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DEFINE SIMPLE ENVIRONMENT AGAIN WITHOUT PRINTING ANY VALUES\n",
        "def simple_environment(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(2, size=(n, n), p=[0.8, 0.2])\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "    #print(\"First Position of the robot:\")\n",
        "    #print(robot_position)\n",
        "    #print(robot_position)\n",
        "    # south_con, north_con, west_con, east_con = robot_position[0] == 4, \n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #define environmental obstacles. For this case, bumpers will only see the\n",
        "      #walls. Dirt sensor is also defined here.\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "        delta, act = agent()\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        #print(\"Number of iteration:\")\n",
        "        #print(i+1)\n",
        "        #print(\"position of robot:\")\n",
        "        #print(robot_position)\n",
        "        #print(\"Action taken:\")\n",
        "        #print(act)\n",
        "        #print(\"Environment status after the action\")\n",
        "        #print(environment)\n",
        "        #print(bumpers)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "\n",
        "    return i+1\n"
      ],
      "metadata": {
        "id": "06rYu9i80wkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5x5 Environment for Random Agent\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EsKflWoS4D2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size_random=list()\n",
        "n=7\n",
        "for i in range(100):\n",
        "    step=simple_environment(n,simple_randomized_agent, max_steps = 1500)\n",
        "    #print(step)\n",
        "    step_size_random.append(step)\n",
        "step_size_reflex = [i for i in step_size_random if i < 999999999999999999]\n",
        "plt.hist(step_size_random, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "eCKTNEwXpTfy",
        "outputId": "45bf4b37-ff89-4949-b533-c2d89a1338e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400.16"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10x10 Environment for Random Agent"
      ],
      "metadata": {
        "id": "pEvuGr0Q4Yip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size_random=list()\n",
        "n=12\n",
        "for i in range(100):\n",
        "    step=simple_environment(n,simple_randomized_agent, max_steps = 100000)\n",
        "    #print(step)\n",
        "    step_size_random.append(step)\n",
        "step_size_reflex = [i for i in step_size_random if i < 999999999999999999]\n",
        "plt.hist(step_size_random, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "FXOpVE8bnaXp",
        "outputId": "d3330ae8-0883-4279-e532-4b7746b1e539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2982.32"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "100x100 Environment for Random Agent"
      ],
      "metadata": {
        "id": "2xUtb8b54dO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size_random=list()\n",
        "n=102\n",
        "for i in range(100):\n",
        "    step=simple_environment(n,simple_randomized_agent, max_steps = 10000000)\n",
        "    #print(step)\n",
        "    step_size_random.append(step)\n",
        "step_size_reflex = [i for i in step_size_random if i < 999999999999999999]\n",
        "plt.hist(step_size_random, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "uZyiqbJYoOfe",
        "outputId": "70d78dab-0cd3-45dd-d7e0-988f5d6546f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "841031.62"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SIMPLE ENVIRONMENT FOR REFLEX AGENT"
      ],
      "metadata": {
        "id": "hWJFJe0p0ocS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJdnT8ItAUTq"
      },
      "outputs": [],
      "source": [
        "#SIMPLE ENVIRONMENT IS DEFINED AGAIN WITHOUT PRINTING ANY VALUES.\n",
        "def simple_environment_2(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(2, size=(n, n), p=[0.8, 0.2])\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "    #print(\"First Position of the robot:\")\n",
        "    #print(robot_position)\n",
        "  #print(robot_position)\n",
        "   # south_con, north_con, west_con, east_con = robot_position[0] == 4, \n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #define environmental obstacles. For this case, bumpers will only see the\n",
        "      #walls. Dirt sensor is also defined here.\n",
        "        #reward_space[robot_position[0]+1][robot_position[1]+1]=reward_space[robot_position[0]][robot_position[1]]+1\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "\n",
        "\n",
        "        if environment[robot_position[0]][robot_position[1]]==1: bumpers[\"dirt\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==0: bumpers[\"dirt\"]=False\n",
        "        act = agent(bumpers)\n",
        "        if act == 'east':\n",
        "          delta = [0,1]\n",
        "        if act == 'west':\n",
        "          delta = [0,-1]\n",
        "        if act == 'south':\n",
        "          delta = [1,0]  \n",
        "        if act == 'suck':\n",
        "          delta = [0,0]\n",
        "        if act == 'north':\n",
        "          delta = [-1,0]\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        #print(\"Number of iteration:\")\n",
        "        #print(i+1)\n",
        "        #print(bumpers)\n",
        "        #print(\"Action taken:\")\n",
        "        #print(act)\n",
        "        #print(\"position of robot:\")\n",
        "        #print(robot_position)\n",
        "        #print(\"Environment status after the action\")\n",
        "        #print(environment)\n",
        "        \n",
        "        #print(reward_space)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "        \n",
        "    return i+1"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JOFHNI-eLe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn3V6ClihNQi"
      },
      "source": [
        "CODE BELOW RETURNS THE NUMBER OF ITERATION NEEDED FOR ROBOT CLEAN THE ENVIRONMENT. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yTcU5SyDqEj",
        "outputId": "6bfe8fb2-b0e1-447b-91b5-745f377ac2c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "n=7\n",
        "simple_environment_2(n,simple_agent, max_steps = 500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Reflex Agent 5X5 Environment"
      ],
      "metadata": {
        "id": "QZ0tOLRSiHcz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIkjYigChNQk",
        "outputId": "2169bfe4-5785-4a01-879d-85090eee0f08"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "114.2"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size=list()\n",
        "n=7\n",
        "for i in range(100):\n",
        "    step=simple_environment_2(n,simple_agent, max_steps = 500)\n",
        "    #print(step)\n",
        "    step_size.append(step)\n",
        "step_size_reflex = [i for i in step_size if i < 999999999999999999]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Reflex Agent 10x10 Environment"
      ],
      "metadata": {
        "id": "KjmNhgjFiPXv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6_NhN42hNQm",
        "outputId": "5975b852-aa01-4863-9e5a-116e3a9fcd4d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "958.23"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size=list()\n",
        "n=12\n",
        "for i in range(100):\n",
        "    step=simple_environment_2(n,simple_agent, max_steps = 3000)\n",
        "    #print(step)\n",
        "    step_size.append(step)\n",
        "step_size_reflex = [i for i in step_size if i < 999999999999999999]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Reflex Agent 100x100 Environment"
      ],
      "metadata": {
        "id": "g7DrZwhgiVPU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dl4FkPmKM-uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0cMzmaEjN5Z",
        "outputId": "27a1cee4-f862-44b9-a47f-dbaf4321373f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "349550.73"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size=list()\n",
        "n=102\n",
        "for i in range(100):\n",
        "    step=simple_environment_2(n,simple_agent, max_steps = 1000000)\n",
        "    #print(step)\n",
        "    step_size.append(step)\n",
        "step_size_reflex = [i for i in step_size if i < 1000000]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Based Agent"
      ],
      "metadata": {
        "id": "GfykG-cC2MMh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daccb44e-9d5f-45fb-9b1a-d8d4820f755f"
      },
      "source": [
        "## model based without obstacle 5x5 environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1b1d18c-110a-416d-8154-3c8e47d6a980"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5b81cb0-2cfb-4139-824a-2645d3519edc"
      },
      "outputs": [],
      "source": [
        "# Your code and description goes here\n",
        "\n",
        "def find_station(n,robot_position,max_steps):\n",
        "    chosen_Act = 'north'\n",
        "    for i in range(max_steps):\n",
        "        # sensors sensing\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        # rationalizing action\n",
        "        if bumpers[chosen_Act] == True: \n",
        "            chosen_Act = 'west' \n",
        "        else: \n",
        "            chosen_Act = chosen_Act\n",
        "        if bumpers[chosen_Act] == True:\n",
        "            #print('arrived at north-west corner')\n",
        "            #print('saving position as (0,0) to memory')\n",
        "            memory_position = robot_position\n",
        "            break\n",
        "        # act upon chosen action\n",
        "        if chosen_Act == 'east':\n",
        "            delta = [0,1]\n",
        "        if chosen_Act == 'west':\n",
        "            delta = [0,-1]\n",
        "        if chosen_Act == 'south':\n",
        "            delta = [1,0]  \n",
        "        if chosen_Act == 'suck':\n",
        "            delta = [0,0]\n",
        "        if chosen_Act == 'north':\n",
        "            delta = [-1,0]         \n",
        "        # changed position\n",
        "        robot_position = robot_position + delta\n",
        "        #print(robot_position)\n",
        "    return robot_position\n",
        "\n",
        "#env = np.random.choice(2, size=(n-2, n-2), p=[0.8, 0.2])\n",
        "\n",
        "def reward_based_movement(robot_position, reward_space, actions):\n",
        "    # put this after possible actions are determined by bumpers!\n",
        "    # robot_position = [0, 0]\n",
        "    # actions = {\"east\" : [0,1], \"south\" : [1,0]}\n",
        "    p_pos, p_reward = list(), list()\n",
        "    p_delta = [j for i,j in actions.items()]\n",
        "    for i in range(len(p_delta)):\n",
        "        p_pos.append(np.array(robot_position) + p_delta[i])\n",
        "        p_reward.append(reward_space[p_pos[-1][0]][p_pos[-1][1]])\n",
        "    idx = p_reward.index(min(p_reward)) # find index of the low reward direction\n",
        "    act = list(actions.keys())[idx]\n",
        "    #print(chosen_Act) \n",
        "    #print(reward_space)\n",
        "    return act\n",
        "\n",
        "def modal_based_agent(n, robot_position, max_steps):\n",
        "    #env = np.random.choice(3, size=(7, 7), p=[0.8, 0.2])\n",
        "    env=np.random.choice(3, size=(n, n), p=[0.75, 0.2, 0.05])\n",
        "    env[0] = [3 for i in range(n)]\n",
        "    env[n-1] = [3 for i in range(n)]\n",
        "    env[:,0] = [3 for i in range(n)]\n",
        "    env[:,n-1]=[3 for i in range(n)]\n",
        "    robot_position_array = list()\n",
        "    reward_space = np.zeros(shape = (n,n))\n",
        "    #print('This is the environment matrix:')\n",
        "    #print(env)\n",
        "    for i in range(max_steps):\n",
        "        # return back all possiblities.\n",
        "        actions = {\"north\" : [-1,0] , \"east\": [0,1], \"west\" : [0,-1], \"south\" : [1, 0]}\n",
        "        reward_space[robot_position[0]][robot_position[1]]=reward_space[robot_position[0]][robot_position[1]]+1\n",
        "        #print(robot_position)\n",
        "        # sensors sensing\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "\n",
        "       \n",
        "        # Obstacle func.  \n",
        "        if env[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if env[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]-1]==2:bumpers[\"west\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]]==1: bumpers[\"suck\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]]==0: bumpers[\"suck\"]=False\n",
        "        #if env[robot_position[0]][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        #if env[robot_position[0]][robot_position[1]]==2:bumpers[\"east\"]=True\n",
        "        #if env[robot_position[0]][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        #if env[robot_position[0]][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        #if env[robot_position[0]][robot_position[1]]==1: bumpers[\"suck\"]=True\n",
        "        #if env[robot_position[0]][robot_position[1]]==0: bumpers[\"suck\"]=False\n",
        "        \n",
        "        # eliminate irrational choices to determine the action: # POSSIBLE ERROR: it can't remove the same thing twice.        \n",
        "        if bumpers[\"suck\"] == True: \n",
        "            chosen_Act = 'suck'\n",
        "            #print('sucking')\n",
        "        else:\n",
        "            if bumpers['south'] ==  True: del actions['south']  # actions.remove('south')\n",
        "            if bumpers['east'] ==  True:  del actions['east']   # actions.remove('east')\n",
        "            if bumpers['west'] ==  True:  del actions['west']   # actions.remove('west')\n",
        "            if bumpers['north'] ==  True: del actions['north']  # actions.remove('north')\n",
        "        \n",
        "        # Choosing rational action        \n",
        "            if i == 0: \n",
        "                chosen_Act = np.random.choice(list(actions.keys()))\n",
        "                #print('first step')  # first action is total random chosen from possible paths.\n",
        "            elif bumpers[chosen_Act] == True: \n",
        "                #print('we are at wall: ',robot_position)\n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions) #reward_based_movement\n",
        "            elif chosen_Act == 'suck': \n",
        "                #print(actions)\n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions)\n",
        "                #print('cleaned: ', robot_position)\n",
        "            else: \n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions)\n",
        "                #print('else condition. pure reward based')\n",
        "            \n",
        "        \n",
        "        # act upon chosen action\n",
        "        if chosen_Act == 'east':\n",
        "            delta = [0,1]\n",
        "        if chosen_Act == 'west':\n",
        "            delta = [0,-1]\n",
        "        if chosen_Act == 'south':\n",
        "            delta = [1,0]  \n",
        "        if chosen_Act == 'suck':\n",
        "            delta = [0,0]\n",
        "        if chosen_Act == 'north':\n",
        "            delta = [-1,0]            \n",
        "        if chosen_Act == 'suck':\n",
        "            env[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "            env=env\n",
        "\n",
        "        #if the environment is clean, break the loop.\n",
        "        #if not np.any(env):\n",
        "        if 1 not in env:\n",
        "            #print('done after:', i+1,'steps')\n",
        "            break\n",
        "        \n",
        "        # Moving to new position\n",
        "        robot_position = robot_position + delta\n",
        "        robot_position_array.append(robot_position)\n",
        "        #print(reward_space) \n",
        "        \n",
        "    return i+1, reward_space          \n",
        "\n",
        "def environment(n):\n",
        "    env = np.random.choice(2, size=(n, n), p=[0.8, 0.2])\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "a1962432-3868-4df6-a6fd-e8f7380e9c0a",
        "outputId": "883c2d19-afcc-4a79-99bb-8dcb11ca7137"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.71"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size = list()\n",
        "for i in range(100):\n",
        "    n = 7\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    robot_position = find_station(n,robot_position,1000000)\n",
        "    step,_ =modal_based_agent(n,robot_position, 1000000)\n",
        "    step_size.append(step)\n",
        "step_size = [i for i in step_size if i < 999999999]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model based without obstacle, 10x10 environment"
      ],
      "metadata": {
        "id": "YvXIlM5-P5gb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "e9b88bb5-643c-48cb-bde7-e65c6ac76745",
        "id": "YPwo68xxQQlh"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216.36"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size = list()\n",
        "for i in range(100):\n",
        "    n = 12\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    robot_position = find_station(n,robot_position,1000000)\n",
        "    step,_ =modal_based_agent(n,robot_position, 1000000)\n",
        "    step_size.append(step)\n",
        "step_size = [i for i in step_size if i < 999999999]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Based 100x100 environment"
      ],
      "metadata": {
        "id": "4wgR-HwuU683"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "55432558-6f09-47a3-e912-fb7af0fb117a",
        "id": "mr4RyMv4QkmN"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235830.375"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size = list()\n",
        "for i in range(100):\n",
        "    n = 102\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    robot_position = find_station(n,robot_position,1000000)\n",
        "    step,_ =modal_based_agent(n,robot_position, 1000000)\n",
        "    step_size.append(step)\n",
        "step_size = [i for i in step_size if i < 500000]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRPeEiY2h4mH"
      },
      "source": [
        "Fill out the following table with the average performance measure for 100 random runs (you may also create this table with code):\n",
        "\n",
        "| Size     | Randomized Agent | Simple Reflex Agent | Model-based Reflex Agent |\n",
        "|----------|------------------|---------------------|--------------------------|\n",
        "| 5x5     |400.16 |114.2 |28.71|\n",
        "| 10x10   |2982.32 |958.23 |216.36 |\n",
        "| 100x100 |841031.62 |349550.73 |235830.375 |\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmhdxI1TezIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size_random=list()\n",
        "n=7\n",
        "for i in range(100):\n",
        "    step=simple_environment(n,simple_randomized_agent, max_steps = 1500)\n",
        "    #print(step)\n",
        "    step_size_random.append(step)\n",
        "step_size_reflex = [i for i in step_size_random if i < 999999999999999999]\n",
        "#plt.hist(step_size_random, bins=5)\n",
        "#plt.show()\n",
        "\n",
        "#print('mean value for number of iterations:')\n",
        "#np.mean(step_size_random)"
      ],
      "metadata": {
        "id": "Hb_kFwJYezXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFQDlFPAezXC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size_reflex=list()\n",
        "n=7\n",
        "for i in range(100):\n",
        "    step=simple_environment_2(n,simple_agent, max_steps = 500)\n",
        "    #print(step)\n",
        "    step_size_reflex.append(step)\n",
        "step_size_reflex = [i for i in step_size_reflex if i < 999999999999999999]\n",
        "#plt.hist(step_size, bins=5)\n",
        "#plt.show()\n",
        "\n",
        "#print('mean value for number of iterations:')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooomT4kPezXC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size = list()\n",
        "for i in range(100):\n",
        "    bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"suck\" : False }\n",
        "    n = 7\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    robot_position = find_station(n,robot_position,1000000)\n",
        "    step,_ =modal_based_agent(n,robot_position, 1000000)\n",
        "    step_size.append(step)\n",
        "step_size = [i for i in step_size if i < 1000]\n",
        "#plt.hist(step_size, bins=5)\n",
        "#plt.show()\n",
        "\n",
        "#print('mean value for number of iterations:')\n",
        "#np.mean(step_size)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(step_size, bins=10)\n",
        "plt.hist(step_size_reflex, bins=10)\n",
        "plt.hist(step_size_random, bins=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "AJRO8Abja-ma",
        "outputId": "18a234d8-8c7c-4422-c133-3559dbb24224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 7., 19., 31., 16., 13.,  7.,  4.,  1.,  1.,  1.]),\n",
              " array([1.0000e+00, 1.4630e+02, 2.9160e+02, 4.3690e+02, 5.8220e+02,\n",
              "        7.2750e+02, 8.7280e+02, 1.0181e+03, 1.1634e+03, 1.3087e+03,\n",
              "        1.4540e+03]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "LE-2xh_GdC1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(step_size_random)\n",
        "sns.kdeplot(step_size)\n",
        "sns.kdeplot(step_size_reflex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0LHHXHJrdpVQ",
        "outputId": "8e1c8366-ff80-4b47-bb65-586562a1f6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f553a426a90>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry2_-1z7h4mH"
      },
      "source": [
        "## Task 5: Robustness of the agent implementations [10 Points] \n",
        "\n",
        "Describe how **your agent implementations** will perform \n",
        "\n",
        "* if it is put into a rectangular room with unknown size, \n",
        "* if the cleaning area can have an iregular shape (e.g., a hallway connecting two rooms), or \n",
        "* if the room contains obstacles (i.e., squares that it cannot pass through and trigger the bumper sensors)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "**Discussion**\n",
        "\n",
        "Performance of random agent will be extremely poor as expected.\n",
        "Simple agent will perform better since it can understand if there is a wall in its neighbor or dirt in its location. However, the movement is still random.\n",
        "We can expect higly poor performances for these 2 models.\n",
        "\n",
        "Model based agent will perform better since it knows where it is and assigns a negative reward value to the locations it has been before. It will dramatically increase performance the performance. \n",
        "\n",
        "An algorithm can be written so that robot first walks through the wall. Let's consider a L shape room. When moving with the wall, wall can disappear suddenly.In this case, rather than random or memory oriented action, agent can go throgh the previous wall direction. With this, robot can go through all the walls of the environment.\n",
        "\n",
        "\n",
        "Obstacle case will be investigated right below:\n",
        "\n",
        "\n",
        "One thing to consider is also when adding random obstacles and random robot position, robot can't decide where to go an exit with an error. We can add an actions such as \"stop\" so that robot close itself if there is no available actions."
      ],
      "metadata": {
        "id": "a-UcxlnT5JAX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gYonBtjh4mH"
      },
      "source": [
        "## Graduate student advanced task: Obstacles [10 Points]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus Points].\n",
        "\n",
        "1. Change your simulation environment tor run experiments for the following problem: Add random obstacle squares that also trigger the bumper sensor. The agent does not know where the obstacles are. Observe how this changes the performance of the three implementations.\n",
        "\n",
        "2. Describe what would need to be done to perform better with obstacles. Add code if you can. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM AGENT WITH OBSTACLE**\n",
        "\n",
        "I changed how the environment array is defined and add values (2). They represent the obstacles"
      ],
      "metadata": {
        "id": "pNZFGEqkA49I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfLWbEnHA89k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#delta represents the displacement value. for every action, displacement value is changed\n",
        "\n",
        "def simple_randomized_agent():\n",
        "    actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
        "    chosen_Act = np.random.choice(actions)\n",
        "    if chosen_Act == 'north':\n",
        "        delta = [-1,0]\n",
        "    if chosen_Act == 'east':\n",
        "        delta = [0,1]\n",
        "    if chosen_Act == 'west':\n",
        "        delta = [0,-1]\n",
        "    if chosen_Act == 'south':\n",
        "        delta = [1,0]  \n",
        "    if chosen_Act == 'suck':\n",
        "        delta = [0,0]\n",
        "    return np.array(delta), chosen_Act\n",
        "    \n",
        "def simple_environment(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(3, size=(n, n), p=[0.7, 0.2, 0.1])\n",
        "    #value 2 should be replaced to 3 if there is any obstacle in the environment and another possibility value should be added.\n",
        "    \n",
        "    #3 represents the walls. First and last column and rows of the environment matrix will be all 3.\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "    #print(\"First Position of the robot:\")\n",
        "    #print(robot_position)\n",
        "    #print(robot_position)\n",
        "    # south_con, north_con, west_con, east_con = robot_position[0] == 4, \n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #Defines sensors for the environment. Bumpers will see the walls(3) and obstacles(2) if there is any.\n",
        "      #This case there are only walls. Dirt sensor is defined inside bumpers matrix and represented\n",
        "      #as one \n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==1: bumpers[\"dirt\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==0: bumpers[\"dirt\"]=False\n",
        "        delta, act = agent()\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        print(\"Number of iteration:\")\n",
        "        print(i+1)\n",
        "        print(\"position of robot:\")\n",
        "        print(robot_position)\n",
        "        print(\"Action taken:\")\n",
        "        print(act)\n",
        "        print(\"Environment status after the action\")\n",
        "        print(environment)\n",
        "        print(bumpers)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "#returns the total action required.\n",
        "    return i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "5af8691a-25e5-4c3a-ebd8-4e83310b9fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3HbS_wbA89m"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iteration:\n",
            "1\n",
            "position of robot:\n",
            "[2 1]\n",
            "Action taken:\n",
            "west\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 1 2 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 2 0 1 3]\n",
            " [3 0 0 0 2 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n",
            "Number of iteration:\n",
            "2\n",
            "position of robot:\n",
            "[3 1]\n",
            "Action taken:\n",
            "south\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 1 2 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 2 0 1 3]\n",
            " [3 0 0 0 2 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n",
            "Number of iteration:\n",
            "3\n",
            "position of robot:\n",
            "[3 1]\n",
            "Action taken:\n",
            "west\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 1 2 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 2 0 1 3]\n",
            " [3 0 0 0 2 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n",
            "Number of iteration:\n",
            "4\n",
            "position of robot:\n",
            "[2 1]\n",
            "Action taken:\n",
            "north\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 1 2 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 2 0 1 3]\n",
            " [3 0 0 0 2 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n",
            "Number of iteration:\n",
            "5\n",
            "position of robot:\n",
            "[2 2]\n",
            "Action taken:\n",
            "east\n",
            "Environment status after the action\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 0 0 1 3]\n",
            " [3 0 1 2 0 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 0 0 2 0 1 3]\n",
            " [3 0 0 0 2 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "{'north': False, 'east': False, 'south': False, 'west': True, 'dirt': False}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "import numpy as np\n",
        "n=7\n",
        "simple_environment(n,simple_randomized_agent, max_steps = 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_environment(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(3, size=(n, n), p=[0.7, 0.2, 0.1])\n",
        "    #value 2 should be replaced to 3 if there is any obstacle in the environment and another possibility value should be added.\n",
        "    \n",
        "    #3 represents the walls. First and last column and rows of the environment matrix will be all 3.\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "    #print(\"First Position of the robot:\")\n",
        "    #print(robot_position)\n",
        "    #print(robot_position)\n",
        "    # south_con, north_con, west_con, east_con = robot_position[0] == 4, \n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #Defines sensors for the environment. Bumpers will see the walls(3) and obstacles(2) if there is any.\n",
        "      #This case there are only walls. Dirt sensor is defined inside bumpers matrix and represented\n",
        "      #as one \n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==1: bumpers[\"dirt\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==0: bumpers[\"dirt\"]=False\n",
        "        delta, act = agent()\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        #print(\"Number of iteration:\")\n",
        "        #print(i+1)\n",
        "        #print(\"position of robot:\")\n",
        "        #print(robot_position)\n",
        "        #print(\"Action taken:\")\n",
        "        #print(act)\n",
        "        #print(\"Environment status after the action\")\n",
        "        #print(environment)\n",
        "        #print(bumpers)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "#returns the total action required.\n",
        "    return i+1"
      ],
      "metadata": {
        "id": "HPWWQfFQYtKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size_random=list()\n",
        "n=7\n",
        "for i in range(100):\n",
        "    step=simple_environment(n,simple_randomized_agent, max_steps = 1500)\n",
        "    #print(step)\n",
        "    step_size_random.append(step)\n",
        "step_size_reflex = [i for i in step_size_random if i < 4000]\n",
        "plt.hist(step_size_random, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "wtrqDOUdYxyH",
        "outputId": "0471aab7-6de5-4c50-8a32-600378e9e7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480.61"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM AGENT PERFORMANCE DROPPED WITH THE OBSTACLE ENVIRONMENT"
      ],
      "metadata": {
        "id": "Utfy0YjKZTPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMPLE REFLEX AGENT WITH OBSTACLES**"
      ],
      "metadata": {
        "id": "7GFbgtGMMUMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM ENVIRONMENT CHOICE IS CHANGED AND OBSTACLES WERE ADDED (2 VALUES IN ENVIRONMENT MATRIX)"
      ],
      "metadata": {
        "id": "MeY1FjTZMdMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYoQvvsnOkoD"
      },
      "outputs": [],
      "source": [
        "def simple_environment_2(n,agent, max_steps, bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"dirt\" : False }):\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    environment=np.random.choice(3, size=(n, n), p=[0.7, 0.2, 0.1])\n",
        "    environment[0] = [3 for i in range(n)]\n",
        "    environment[n-1] = [3 for i in range(n)]\n",
        "    environment[:,0] = [3 for i in range(n)]\n",
        "    environment[:,n-1]=[3 for i in range(n)]\n",
        "    #print(\"First Position of the robot:\")\n",
        "    #print(robot_position)\n",
        "  #print(robot_position)\n",
        "   # south_con, north_con, west_con, east_con = robot_position[0] == 4, \n",
        "    \n",
        "    for i in range(max_steps): \n",
        "      #define environmental obstacles. For this case, bumpers will only see the\n",
        "      #walls. Dirt sensor is also defined here.\n",
        "        #reward_space[robot_position[0]+1][robot_position[1]+1]=reward_space[robot_position[0]][robot_position[1]]+1\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        if environment[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if environment[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]-1]==2:bumpers[\"north\"]=True\n",
        "\n",
        "\n",
        "        if environment[robot_position[0]][robot_position[1]]==1: bumpers[\"dirt\"]=True\n",
        "        if environment[robot_position[0]][robot_position[1]]==0: bumpers[\"dirt\"]=False\n",
        "        act = agent(bumpers)\n",
        "        if act == 'east':\n",
        "          delta = [0,1]\n",
        "        if act == 'west':\n",
        "          delta = [0,-1]\n",
        "        if act == 'south':\n",
        "          delta = [1,0]  \n",
        "        if act == 'suck':\n",
        "          delta = [0,0]\n",
        "        if act == 'north':\n",
        "          delta = [-1,0]\n",
        "        #print(robot_position, act)\n",
        "        if act=='suck':\n",
        "           environment[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "           environment=environment\n",
        "        if (bumpers[\"north\"] == True) and (act == 'north'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"south\"] == True) and (act == 'south'):\n",
        "            robot_position = robot_position\n",
        "        elif (bumpers[\"east\"] == True) and (act == 'east'):\n",
        "            robot_position = robot_position \n",
        "        elif (bumpers[\"west\"] == True) and (act == 'west'):\n",
        "            robot_position = robot_position \n",
        "        else:\n",
        "            robot_position = robot_position + delta\n",
        "      \n",
        "        #print(\"Number of iteration:\")\n",
        "        #print(i+1)\n",
        "        #print(bumpers)\n",
        "        #print(\"Action taken:\")\n",
        "        #print(act)\n",
        "        #print(\"position of robot:\")\n",
        "        #print(robot_position)\n",
        "        #print(\"Environment status after the action\")\n",
        "        #print(environment)\n",
        "        \n",
        "        #print(reward_space)\n",
        "        #if the environment is clean, break the loop.\n",
        "        if 1 not in environment:\n",
        "            break\n",
        "        \n",
        "    return i+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZpPLsxlOkoR"
      },
      "source": [
        "Simple Agent 5X5 Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "0ac9e821-5fda-4450-efde-b58f31981aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "3A6GF5yjOkoR"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137.76"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size=list()\n",
        "n=7\n",
        "for i in range(100):\n",
        "    step=simple_environment_2(n,simple_agent, max_steps = 500)\n",
        "    #print(step)\n",
        "    step_size.append(step)\n",
        "step_size_reflex = [i for i in step_size if i < 999999999999999999]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT SHOWS SLIGHTLY LESS PERFORMANCE IN THE OBSTACLE ENVIRONMENT."
      ],
      "metadata": {
        "id": "tCDGLtEKO2Vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL BASED AGENT WITH OBSTACLES:**"
      ],
      "metadata": {
        "id": "LRTu7CbCI40_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Obstacles. Since I already implemented that sensors will recognized obstacles in environment array (2 values), there is no need to change anything in agent part."
      ],
      "metadata": {
        "id": "6PB8UGuVL5W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju25424iL6Xa"
      },
      "outputs": [],
      "source": [
        "# Your code and description goes here\n",
        "\n",
        "bumpers = {\"north\" : False, \"east\" : False, \"south\" : False, \"west\" : False, \"suck\" : False }\n",
        "    \n",
        "def find_station(n,robot_position,max_steps):\n",
        "    chosen_Act = 'north'\n",
        "    for i in range(max_steps):\n",
        "        # sensors sensing\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "        # rationalizing action\n",
        "        if bumpers[chosen_Act] == True: \n",
        "            chosen_Act = 'west' \n",
        "        else: \n",
        "            chosen_Act = chosen_Act\n",
        "        if bumpers[chosen_Act] == True:\n",
        "            #print('arrived at north-west corner')\n",
        "            #print('saving position as (0,0) to memory')\n",
        "            memory_position = robot_position\n",
        "            break\n",
        "        # act upon chosen action\n",
        "        if chosen_Act == 'east':\n",
        "            delta = [0,1]\n",
        "        if chosen_Act == 'west':\n",
        "            delta = [0,-1]\n",
        "        if chosen_Act == 'south':\n",
        "            delta = [1,0]  \n",
        "        if chosen_Act == 'suck':\n",
        "            delta = [0,0]\n",
        "        if chosen_Act == 'north':\n",
        "            delta = [-1,0]         \n",
        "        # changed position\n",
        "        robot_position = robot_position + delta\n",
        "        #print(robot_position)\n",
        "    return robot_position\n",
        "\n",
        "#env = np.random.choice(2, size=(n-2, n-2), p=[0.8, 0.2])\n",
        "\n",
        "def reward_based_movement(robot_position, reward_space, actions):\n",
        "    # put this after possible actions are determined by bumpers!\n",
        "    # robot_position = [0, 0]\n",
        "    # actions = {\"east\" : [0,1], \"south\" : [1,0]}\n",
        "    p_pos, p_reward = list(), list()\n",
        "    p_delta = [j for i,j in actions.items()]\n",
        "    for i in range(len(p_delta)):\n",
        "        p_pos.append(np.array(robot_position) + p_delta[i])\n",
        "        p_reward.append(reward_space[p_pos[-1][0]][p_pos[-1][1]])\n",
        "    idx = p_reward.index(min(p_reward)) # find index of the low reward direction\n",
        "    act = list(actions.keys())[idx]\n",
        "    #print(chosen_Act) \n",
        "    #print(reward_space)\n",
        "    return act\n",
        "\n",
        "def modal_based_agent(n, robot_position, max_steps):\n",
        "    #env = np.random.choice(3, size=(7, 7), p=[0.8, 0.2])\n",
        "    env=np.random.choice(3, size=(n, n), p=[0.7, 0.2, 0.1])\n",
        "    env[0] = [3 for i in range(n)]\n",
        "    env[n-1] = [3 for i in range(n)]\n",
        "    env[:,0] = [3 for i in range(n)]\n",
        "    env[:,n-1]=[3 for i in range(n)]\n",
        "    print('First Environment')\n",
        "    print(env)\n",
        "    robot_position_array = list()\n",
        "    reward_space = np.zeros(shape = (n,n))\n",
        "    #print('This is the environment matrix:')\n",
        "    #print(env)\n",
        "    for i in range(max_steps):\n",
        "        # return back all possiblities.\n",
        "        actions = {\"north\" : [-1,0] , \"east\": [0,1], \"west\" : [0,-1], \"south\" : [1, 0]}\n",
        "        reward_space[robot_position[0]][robot_position[1]]=reward_space[robot_position[0]][robot_position[1]]+1\n",
        "        #print(robot_position)\n",
        "        # sensors sensing\n",
        "        if robot_position[0] == n-2: bumpers[\"south\"] = True\n",
        "        if robot_position[0] != n-2: bumpers[\"south\"] = False \n",
        "        if robot_position[1] == n-2: bumpers[\"east\"] = True\n",
        "        if robot_position[1] != n-2: bumpers[\"east\"] = False\n",
        "        if robot_position[1] == 1: bumpers[\"west\"] = True\n",
        "        if robot_position[1] != 1: bumpers[\"west\"] = False\n",
        "        if robot_position[0] == 1: bumpers[\"north\"] = True\n",
        "        if robot_position[0] != 1: bumpers[\"north\"] = False\n",
        "\n",
        "       \n",
        "        # Obstacle func.  \n",
        "        if env[robot_position[0]-1][robot_position[1]]==2:bumpers[\"north\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]+1]==2:bumpers[\"east\"]=True\n",
        "        if env[robot_position[0]+1][robot_position[1]]==2:bumpers[\"south\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]-1]==2:bumpers[\"west\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]]==1: bumpers[\"suck\"]=True\n",
        "        if env[robot_position[0]][robot_position[1]]==0: bumpers[\"suck\"]=False\n",
        "\n",
        "        \n",
        "        # eliminate irrational choices to determine the action: # POSSIBLE ERROR: it can't remove the same thing twice.        \n",
        "        if bumpers[\"suck\"] == True: \n",
        "            chosen_Act = 'suck'\n",
        "            #print('sucking')\n",
        "        else:\n",
        "            if bumpers['south'] ==  True: del actions['south']  # actions.remove('south')\n",
        "            if bumpers['east'] ==  True:  del actions['east']   # actions.remove('east')\n",
        "            if bumpers['west'] ==  True:  del actions['west']   # actions.remove('west')\n",
        "            if bumpers['north'] ==  True: del actions['north']  # actions.remove('north')\n",
        "        \n",
        "        # Choosing rational action        \n",
        "            if i == 0: \n",
        "                chosen_Act = np.random.choice(list(actions.keys()))\n",
        "                #print('first step')  # first action is total random chosen from possible paths.\n",
        "            elif bumpers[chosen_Act] == True: \n",
        "                #print('we are at wall: ',robot_position)\n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions) #reward_based_movement\n",
        "            elif chosen_Act == 'suck': \n",
        "                #print(actions)\n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions)\n",
        "                #print('cleaned: ', robot_position)\n",
        "            else: \n",
        "                chosen_Act = reward_based_movement(robot_position,reward_space, actions)\n",
        "                #print('else condition. pure reward based')\n",
        "            \n",
        "        \n",
        "        # act upon chosen action\n",
        "        if chosen_Act == 'east':\n",
        "            delta = [0,1]\n",
        "        if chosen_Act == 'west':\n",
        "            delta = [0,-1]\n",
        "        if chosen_Act == 'south':\n",
        "            delta = [1,0]  \n",
        "        if chosen_Act == 'suck':\n",
        "            delta = [0,0]\n",
        "        if chosen_Act == 'north':\n",
        "            delta = [-1,0]            \n",
        "        if chosen_Act == 'suck':\n",
        "            env[robot_position[0]][robot_position[1]]=0\n",
        "        else:\n",
        "            env=env\n",
        "\n",
        "        #if the environment is clean, break the loop.\n",
        "        #if not np.any(env):\n",
        "        if 1 not in env:\n",
        "            print('Environment is clean:', i+1,'steps')\n",
        "            print(env)\n",
        "            break\n",
        "        \n",
        "        # Moving to new position\n",
        "        robot_position = robot_position + delta\n",
        "        robot_position_array.append(robot_position)\n",
        "        #print(reward_space) \n",
        "        \n",
        "    return i+1, reward_space          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8e2bc3-a87a-4012-971f-f546ac5b3199",
        "outputId": "363c8793-df43-49f9-d846-17b97db180e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Environment\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 2 0 0 3]\n",
            " [3 1 0 0 0 2 3]\n",
            " [3 2 0 1 0 0 3]\n",
            " [3 2 0 0 2 1 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n",
            "Environment is clean: 30 steps\n",
            "[[3 3 3 3 3 3 3]\n",
            " [3 0 0 2 0 0 3]\n",
            " [3 0 0 0 0 2 3]\n",
            " [3 2 0 0 0 0 3]\n",
            " [3 2 0 0 2 0 3]\n",
            " [3 0 0 0 0 0 3]\n",
            " [3 3 3 3 3 3 3]]\n"
          ]
        }
      ],
      "source": [
        " \n",
        "n=7 \n",
        "robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "robot_position = find_station(n,robot_position,1000000)\n",
        "step,_ =modal_based_agent(n,robot_position, 1000000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_size = list()\n",
        "for i in range(100):\n",
        "    n = 7\n",
        "    robot_position = np.random.choice([i for i in range(1,n-1)], size=(1, 2))[0]\n",
        "    robot_position = find_station(n,robot_position,1000000)\n",
        "    step,_ =modal_based_agent(n,robot_position, 1000000)\n",
        "    step_size.append(step)\n",
        "    "
      ],
      "metadata": {
        "id": "rlNC2480JNHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b77e2857-8d40-4616-9c02-c196608e87e5",
        "outputId": "b33d8ca6-ee42-43ea-bafc-a2bdb3f0cd4e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean value for number of iterations:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "30.20408163265306"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "step_size = [i for i in step_size if i < 700000]\n",
        "plt.hist(step_size, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('mean value for number of iterations:')\n",
        "np.mean(step_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL AGENT SHOWS SLIGHTLY LESS PERFORMANCE IN THE OBSTACLE ENVIRONMENT."
      ],
      "metadata": {
        "id": "vrd25ZJdWQCb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pugyb52Rh4mI"
      },
      "source": [
        "## More advanced implementation tasks\n",
        "\n",
        "* __Agent for and environment with obstacles:__ Implement an agent for an environment where the agent does not know how large the environment is (we assume it is rectangular), where it starts or where the obstacles are. An option would be to always move to the closest unchecked/uncleaned square (note that this is actualy depth-first search).\n",
        "\n",
        "* __Utility-based agent:__ Change the environment for a $5 \\times 5$ room, so each square has a fixed probability of getting dirty again. For the implementation, we give the environment a 2-dimensional array of probabilities. The utility of a state is defined as the number of currebntly clean squares in the room. Implement a utility-based agent that maximizes the expected utility over one full charge which lasts for 100000 time steps. To do this, the agent needs to learn the probabilities with which different squares get dirty again. This is very tricky!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I3LGrorh4mI"
      },
      "outputs": [],
      "source": [
        "# The negative rewward implemented for this homework should not be used if points can go dirty again. A possible case solution would be  \n",
        "#go thorugh all the room, then go to reverse positions and clean the dirts.\n",
        "#Learning of probablitites can be achieved this way."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc-autonumbering": false,
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}